{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae94187",
   "metadata": {},
   "source": [
    "# Prévision du prix de l’électricité – Notebook de l’expert\n",
    "\n",
    "Ce notebook présente une solution complète pour le ChallengeData d’Elmy portant sur la prédiction du prix de l’électricité. Nous détaillons chaque étape du processus : chargement des données, analyse exploratoire, préparation du jeu de données, entraînement d’un modèle de classification (XGBoost) et génération des prédictions. Le code est commenté en français et modulaire, prêt à l’emploi dans un Jupyter Notebook classique. Les bibliothèques utilisées incluent pandas, numpy, seaborn, matplotlib, xgboost, scikit-learn et openpyxl.\n",
    "\n",
    "## 1. Chargement des données\n",
    "\n",
    "On commence par importer les bibliothèques nécessaires et charger les fichiers Excel fournis. Ici, openpyxl est spécifié comme moteur pour read_excel, afin d’assurer la compatibilité avec les fichiers .xlsx. Nous vérifions ensuite la taille des données chargées (nombre de lignes et colonnes) pour chaque jeu de données (X_train, Y_train, X_test, Y_random).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2815e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques principales\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Chargement des fichiers Excel (X_train, Y_train, X_test, Y_random)\n",
    "\n",
    "X_train = pd.read_excel('C:\\Users\\julie\\OneDrive - CentraleSupelec\\casablanca\\COURS\\ML\\PROJET LIL\\X_train_Wwou3IE.csv', engine='openpyxl')\n",
    "Y_train = pd.read_excel('C:\\Users\\julie\\OneDrive - CentraleSupelec\\casablanca\\COURS\\ML\\PROJET LIL\\y_train_jJtXgMX.csv', engine='openpyxl')\n",
    "X_test = pd.read_excel('C:\\Users\\julie\\OneDrive - CentraleSupelec\\casablanca\\COURS\\ML\\PROJET LIL\\X_test_GgyECq8.csv', engine='openpyxl')\n",
    "Y_random = pd.read_excel('C:\\Users\\julie\\OneDrive - CentraleSupelec\\casablanca\\COURS\\ML\\PROJET LIL\\y_random_pt8afo8.csv', engine='openpyxl')\n",
    "\n",
    "# Aperçu des dimensions des jeux de données\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_random shape:\", Y_random.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff66ba5",
   "metadata": {},
   "source": [
    "## 2. Analyse exploratoire des données\n",
    "Nous explorons les données pour mieux les comprendre. On examine les types de variables, la présence de valeurs manquantes, et des statistiques descriptives. On regarde également les corrélations entre variables numériques. Enfin, on étudie la distribution de la variable cible d’origine spot_id_delta dans Y_train.\n",
    "\n",
    "### Aperçu des types et de l'échantillon de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Types de variables X_train :\\n\", X_train.dtypes)\n",
    "print(\"\\nAperçu de X_train :\")\n",
    "display(X_train.head())\n",
    "\n",
    "print(\"\\nTypes de variables Y_train :\\n\", Y_train.dtypes)\n",
    "print(\"\\nAperçu de Y_train :\")\n",
    "display(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4640d",
   "metadata": {},
   "source": [
    "### Recherche de valeurs manquantes dans X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a04213",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = X_train.isnull().sum()\n",
    "print(\"\\nValeurs manquantes par colonne dans X_train :\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2015a",
   "metadata": {},
   "source": [
    "### Statistiques descriptives sur X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a51d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStatistiques descriptives de X_train :\")\n",
    "display(X_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0ffa9",
   "metadata": {},
   "source": [
    "### Corrélation entre variables numériques (X_train + Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ae3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([X_train, Y_train], axis=1)\n",
    "corr_matrix = data_concat.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Matrice de corrélation (variables numériques + cible)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365bd85",
   "metadata": {},
   "source": [
    "Ensuite, on examine spécifiquement la distribution de la variable cible d’origine spot_id_delta, afin de voir par exemple si elle suit une loi normale ou si elle est centrée autour de zéro.\n",
    "\n",
    "### Distribution de la variable cible continue spot_id_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be670750",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(Y_train['spot_id_delta'], bins=50, kde=True)\n",
    "plt.title(\"Distribution de spot_id_delta dans Y_train\")\n",
    "plt.xlabel(\"spot_id_delta\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216ef37",
   "metadata": {},
   "source": [
    "## 3. Transformation de la cible en variable binaire\n",
    "\n",
    "La variable cible spot_id_delta est transformée en variable binaire spot_id_delta_binary : elle vaut 1 si spot_id_delta est positif (supérieur à 0), et 0 sinon (négatif ou zéro). On ajoute cette colonne à Y_train et vérifie l’équilibre des classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a89c3",
   "metadata": {},
   "source": [
    "### Création d'une cible binaire : 1 si spot_id_delta > 0, 0 sinon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train['spot_id_delta_binary'] = (Y_train['spot_id_delta'] > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a30cb",
   "metadata": {},
   "source": [
    "### Vérification de la répartition des classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Y_train['spot_id_delta_binary'].value_counts()\n",
    "print(\"Répartition des classes (0 vs 1) :\")\n",
    "print(counts)\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.countplot(x='spot_id_delta_binary', data=Y_train)\n",
    "plt.title(\"Nombre de cas 0 et 1 dans la cible binaire\")\n",
    "plt.xlabel(\"spot_id_delta_binary\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b06def",
   "metadata": {},
   "source": [
    "\n",
    "Cette transformation fait de notre problème un problème de classification binaire. On constate ainsi la proportion d’exemples positifs et négatifs.\n",
    "\n",
    "## 4. Prétraitement des données\n",
    "\n",
    "### 4.1 Encodage de la date\n",
    "\n",
    "La colonne DELIVERY_START contient une date/heure. Nous convertissons cette colonne au format datetime et en extrayons des caractéristiques utiles, comme l’heure de la journée (hour) et le jour de la semaine (dayofweek). Nous pourrons ainsi intégrer l’effet temporel dans le modèle. Après extraction, on peut supprimer la colonne originale DELIVERY_START si elle n’apporte pas d’information supplémentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf69de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_dates(df):\n",
    "    \"\"\"\n",
    "    Convertit la colonne DELIVERY_START en datetime et en extrait les composantes heure et jour de la semaine.\n",
    "    La colonne originale DELIVERY_START est ensuite supprimée.\n",
    "    \"\"\"\n",
    "    # Conversion en datetime\n",
    "    df['DELIVERY_START'] = pd.to_datetime(df['DELIVERY_START'])\n",
    "    # Extraction de l'heure et du jour de la semaine (0 = lundi)\n",
    "    df['hour'] = df['DELIVERY_START'].dt.hour\n",
    "    df['day_of_week'] = df['DELIVERY_START'].dt.dayofweek\n",
    "    # Suppression de la colonne initiale\n",
    "    df.drop(columns=['DELIVERY_START'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9869b4",
   "metadata": {},
   "source": [
    "#### Application de l'encodage sur X_train et X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder_dates(X_train)\n",
    "X_test = encoder_dates(X_test)\n",
    "print(\"Colonnes X_train après encodage des dates :\", X_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39451c5",
   "metadata": {},
   "source": [
    "### 4.2 Autres prétraitements éventuels\n",
    "\n",
    "On vérifie à nouveau la présence éventuelle de valeurs manquantes après encodage et on les traite (par exemple, on pourrait les imputer ou simplement retirer les lignes manquantes). Pour ce notebook, nous supposons qu’il n’y a pas de valeurs manquantes critiques après cette étape, ou bien qu’elles sont peu nombreuses. Si nécessaire, on pourrait imputer des valeurs ou supprimer des colonnes entières.\n",
    "\n",
    "#### Vérification des valeurs manquantes après prétraitement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_train = X_train.isnull().sum().sum()\n",
    "missing_test = X_test.isnull().sum().sum()\n",
    "print(f\"Nombre total de valeurs manquantes dans X_train (après prétraitement) : {missing_train}\")\n",
    "print(f\"Nombre total de valeurs manquantes dans X_test (après prétraitement) : {missing_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60dc6d",
   "metadata": {},
   "source": [
    "Si on trouvait des valeurs manquantes importantes, on les traiterait ici, par exemple avec :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e015e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : imputation par la médiane pour les colonnes numériques (non exécuté si pas de NaN)\n",
    "\n",
    "# X_train.fillna(X_train.median(), inplace=True)\n",
    "# X_test.fillna(X_train.median(), inplace=True)  # on utilise la médiane du train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c634d",
   "metadata": {},
   "source": [
    "### 4.3 Séparation en jeu d’entraînement et de validation\n",
    "\n",
    "Nous séparons ensuite le jeu X_train prétraité et la cible binaire Y_train['spot_id_delta_binary'] en un sous-jeu d’entraînement (X_train_sub, y_train_sub) et un sous-jeu de validation (X_val, y_val). Cela nous permettra d’évaluer le modèle sur des données non vues pendant l’entraînement. Ici, on utilise par exemple 80% pour l’entraînement et 20% pour la validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970f779",
   "metadata": {},
   "source": [
    "#### Séparation des données en train/validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d795026",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train, Y_train['spot_id_delta_binary'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Forme de X_train_sub :\", X_train_sub.shape)\n",
    "print(\"Forme de X_val :\", X_val.shape)\n",
    "print(\"Forme de y_train_sub :\", y_train_sub.shape)\n",
    "print(\"Forme de y_val :\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c6f93",
   "metadata": {},
   "source": [
    "## 5. Entraînement du modèle de classification (XGBoost)\n",
    "\n",
    "Nous entraînons un modèle de XGBoost pour la classification binaire. XGBoost est bien adapté aux données tabulaires et gère les interactions entre les variables. On crée un classifieur XGBClassifier de base et on l’ajuste sur nos données d’entraînement. On peut spécifier random_state pour la reproductibilité et éventuellement régler d’autres hyperparamètres (nombre d’arbres, profondeur, etc.), mais nous prenons les valeurs par défaut pour cette démonstration.\n",
    "\n",
    "#### Création et entraînement du classifieur XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc92ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_clf.fit(X_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34021b",
   "metadata": {},
   "source": [
    "#### Prédiction sur le jeu de validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae284a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = xgb_clf.predict(X_val)\n",
    "print(\"Prédiction effectuée sur le jeu de validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7bbfe",
   "metadata": {},
   "source": [
    "## 6. Évaluation avec la métrique Weighted Accuracy\n",
    "\n",
    "La métrique d’évaluation du challenge est la Weighted Accuracy. Nous définissons une fonction personnalisée weighted_accuracy qui calcule ce score. Par convention, on peut pondérer davantage la classe positive (valeur 1) pour compenser un éventuel déséquilibre. Par exemple, on utilise ici un poids w=5 sur la classe positive :\n",
    "$$\n",
    "\\text{Weighted Accuracy} = \\frac{\\text{WTP} + \\text{WTN}}{\\text{WTP} + \\text{WTN} + \\text{WFP} + \\text{WFN}}\n",
    "$$\n",
    "\n",
    "avec :\n",
    "- WTP = somme des $|y_i|$ pour les vrais positifs,\n",
    "- WTN = somme des $|y_i|$ pour les vrais négatifs,\n",
    "- WFP = somme des $|y_i|$ pour les faux positifs,\n",
    "- WFN = somme des $|y_i|$ pour les faux négatifs. est vraie et 0 sinon,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a23689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred, weight=5):\n",
    "    \"\"\"\n",
    "    Calcule la Weighted Accuracy :\n",
    "    (w * TP + TN) / (w * (TP + FN) + (TN + FP))\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    wa = (weight * tp + tn) / (weight * (tp + fn) + (tn + fp))\n",
    "    return wa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a496e4",
   "metadata": {},
   "source": [
    "#### Calcul du score sur la validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_score = weighted_accuracy(y_val, y_pred_val, weight=5)\n",
    "print(f\"Weighted Accuracy sur le jeu de validation : {wa_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ace76",
   "metadata": {},
   "source": [
    "On affiche également la matrice de confusion et d’autres métriques classiques pour comprendre les performances :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e7afe",
   "metadata": {},
   "source": [
    "#### Matrice de confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "print(\"Matrice de confusion (validation) :\")\n",
    "print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de4d68",
   "metadata": {},
   "source": [
    "#### Rapport de classification standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a870268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_val, y_pred_val, target_names=['Classe 0', 'Classe 1']))\n",
    "print(\"Accuracy simple :\", accuracy_score(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5a20b",
   "metadata": {},
   "source": [
    "## 7. Prédictions finales sur X_test\n",
    "\n",
    "Après évaluation satisfaisante, on applique le même prétraitement à X_test (encodage des dates déjà fait) et on utilise le modèle entraîné pour prédire la classe binaire sur les nouvelles données.\n",
    "\n",
    "#### Prédiction sur X_test (après prétraitement des dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ae1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "print(\"Prédictions finalisées sur X_test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db8594",
   "metadata": {},
   "source": [
    "## 8. Création du fichier de soumission\n",
    "\n",
    "Enfin, on prépare le fichier de soumission ma_submission.csv avec deux colonnes : Id et prediction. On utilise la colonne Id de X_test (ou l’index si aucune colonne Id n’est présente) et la prédiction binaire correspondante. On enregistre le fichier au format CSV sans index supplémentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du DataFrame de soumission\n",
    "\n",
    "if 'Id' in X_test.columns:\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': X_test['Id'],\n",
    "        'prediction': y_test_pred\n",
    "    })\n",
    "else:\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': X_test.index,\n",
    "        'prediction': y_test_pred\n",
    "    })\n",
    "\n",
    "# Sauvegarde au format CSV\n",
    "submission.to_csv('ma_submission.csv', index=False)\n",
    "print(\"Fichier de soumission 'ma_submission.csv' créé avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834fc2a",
   "metadata": {},
   "source": [
    "\n",
    "Le fichier ma_submission.csv contient ainsi, pour chaque identifiant, la prédiction binaire (0 ou 1) correspondant à notre modèle.\n",
    "Ce notebook fournit un pipeline complet, depuis le chargement des données jusqu’à l’enregistrement des prédictions. Les commentaires et les explications détaillées facilitent la compréhension du flux de travail, et le code est structuré en sections claires pour être facilement reproductible dans un environnement Jupyter."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
